{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from arguments import get_config\n",
    "from interfaces import setup_LMP\n",
    "from visualizers import ValueMapVisualizer\n",
    "# from envs.rlbench_env import VoxPoserRLBench\n",
    "from envs.rlbench_env import VoxPoserRLBench2Robots\n",
    "from utils import set_lmp_objects\n",
    "import numpy as np\n",
    "from rlbench import tasks\n",
    "\n",
    "openai.api_key = 'REPLACE-ME'  # set your API key here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "## voxel resolution: [0.0105 0.0131 0.01  ]\n",
      "##################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = get_config('rlbench')\n",
    "# uncomment this if you'd like to change the language model (e.g., for faster speed or lower cost)\n",
    "for lmp_name, cfg in config['lmp_config']['lmps'].items():\n",
    "    cfg['model'] = 'gpt-3.5-turbo'\n",
    "\n",
    "# initialize env and voxposer ui\n",
    "visualizer = ValueMapVisualizer(config['visualizer'])\n",
    "env = VoxPoserRLBench2Robots(visualizer=visualizer)\n",
    "lmps, lmp_env = setup_LMP(env, config, debug=False)\n",
    "voxposer_ui = lmps['plan_ui']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n",
    "\n",
    "By default we use one of the instructions that come with each task. However, you may treat each task as simply a scene initialization from RLBench, and feel free to try any task you can come up with for the scene.\n",
    "\n",
    "Note:\n",
    "- Whether an instruction can be executed or not depends on 1) whether relevant objects are available, and 2) capabilities of the overall algorithm.\n",
    "- Each execution may produce one or more visualizations. You may view them in \"./visualizations/\" folder.\n",
    "- The prompts are adapted with minimal change from the real-world environment in the VoxPoser paper. If a task failure is due to incorrect code generated by the LLM, feel free to modify the relevant prompt in \"./prompts/\" folder.\n",
    "- You may view the reward by printing \"env.latest_reward\". These are computed by RLBench for each task.\n",
    "- To inspect in viewer without performing any action, you may call \"env.rlbench_env._scene.step()\" in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment this to show all available tasks in rlbench\n",
    "# # NOTE: in order to run a new task, you need to add the list of objects (and their corresponding env names) to the \"task_object_names.json\" file. See README for more details.\n",
    "# print([task for task in dir(tasks) if task[0].isupper() and not '_' in task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are the tasks that have object names added to the \"task_object_names.json\" file\n",
    "# uncomment one to use\n",
    "env.load_task(tasks.OpenJar)\n",
    "# env.load_task(tasks.PutRubbishInBin)\n",
    "# env.load_task(tasks.LampOff)\n",
    "# env.load_task(tasks.OpenWineBottle)\n",
    "# env.load_task(tasks.PushButton)\n",
    "# env.load_task(tasks.TakeOffWeighingScales)\n",
    "# env.load_task(tasks.MeatOffGrill)\n",
    "# env.load_task(tasks.SlideBlockToTarget)\n",
    "# env.load_task(tasks.TakeLidOffSaucepan)\n",
    "# env.load_task(tasks.TakeUmbrellaOutOfUmbrellaStand)\n",
    "\n",
    "descriptions, obs = env.reset()\n",
    "set_lmp_objects(lmps, env.get_object_names())  # set the object names to be used by voxposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** OpenAI API call took 12.60s ***\n",
      "########################################\n",
      "## \"planner\" generated code\n",
      "## context: \"objects = ['jar', 'lid', 'jar bottle']\"\n",
      "########################################\n",
      "objects = [\u001b[33m'\u001b[39;49;00m\u001b[33mjar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Query: grasp the jar bottle with left hand and grasp the lid of the orange jar with right hand to unscrew it in an anti_clockwise direction until it is removed from the jar.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "composer(\u001b[33m\"\u001b[39;49;00m\u001b[33mgrasp the jar bottle with left hand\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "composer(\u001b[33m\"\u001b[39;49;00m\u001b[33mgrasp the lid of the orange jar with right hand\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "composer(\u001b[33m\"\u001b[39;49;00m\u001b[33munscrew the lid in an anti-clockwise direction until it is removed from the jar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"composer\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: grasp the jar bottle with left hand.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "movable = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mleft hand\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "affordance_map = get_affordance_map(\u001b[33m'\u001b[39;49;00m\u001b[33ma point at the center of the jar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "gripper_map = get_gripper_map(\u001b[33m'\u001b[39;49;00m\u001b[33mopen everywhere except 1cm around the jar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "execute(movable, affordance_map=affordance_map, gripper_map=gripper_map)\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"parse_query_obj\" generated code\n",
      "## context: \"objects = ['jar', 'lid', 'jar bottle']\"\n",
      "########################################\n",
      "objects = [\u001b[33m'\u001b[39;49;00m\u001b[33mjar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Query: left hand.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "left_hand = detect(\u001b[33m'\u001b[39;49;00m\u001b[33mleft hand\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ret_val = left_hand\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"get_affordance_map\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: a point at the center of the jar bottle.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "affordance_map = get_empty_affordance_map()\u001b[37m\u001b[39;49;00m\n",
      "jar_bottle = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "x, y, z = jar_bottle.position\u001b[37m\u001b[39;49;00m\n",
      "affordance_map[x, y, z] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "ret_val = affordance_map\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"get_gripper_map\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: open everywhere except 1cm around the jar bottle.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "jar_bottle = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "set_voxel_by_radius(gripper_map, jar_bottle.position, radius_cm=\u001b[34m1\u001b[39;49;00m, value=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ret_val = gripper_map\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"parse_query_obj\" generated code\n",
      "## context: \"objects = ['jar', 'lid', 'jar bottle']\"\n",
      "########################################\n",
      "objects = [\u001b[33m'\u001b[39;49;00m\u001b[33mjar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Query: jar bottle.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "jar_bottle = detect(\u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ret_val = jar_bottle\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/envs/rlbench_env.py\u001b[0m(554)\u001b[0;36mget_3d_obs_by_name\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    552 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m    553 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 554 \u001b[0;31m        \u001b[0;32massert\u001b[0m \u001b[0mquery_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname2ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unknown object name: {query_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    555 \u001b[0;31m        \u001b[0mobj_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname2ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    556 \u001b[0;31m        \u001b[0;31m# gather points and masks from all cameras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  self.name2ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jar': [94, 95, 152], 'lid': [95]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing code:\n",
      "movable = parse_query_obj('left hand')\n",
      "affordance_map = get_affordance_map('a point at the center of the jar bottle')\n",
      "gripper_map = get_gripper_map('open everywhere except 1cm around the jar bottle')\n",
      "execute(movable, affordance_map=affordance_map, gripper_map=gripper_map)\n",
      "Error executing code:\n",
      "objects = ['jar', 'lid', 'jar bottle']\n",
      "composer(\"grasp the jar bottle with left hand\")\n",
      "composer(\"grasp the lid of the orange jar with right hand\")\n",
      "composer(\"unscrew the lid in an anti-clockwise direction until it is removed from the jar\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"composer\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: grasp the jar bottle with left hand.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "movable = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mleft hand\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "affordance_map = get_affordance_map(\u001b[33m'\u001b[39;49;00m\u001b[33ma point at the center of the jar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "gripper_map = get_gripper_map(\u001b[33m'\u001b[39;49;00m\u001b[33mopen everywhere except 1cm around the jar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "execute(movable, affordance_map=affordance_map, gripper_map=gripper_map)\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/LMP.py\u001b[0m(187)\u001b[0;36mexec_safe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    185 \u001b[0;31m    ])\n",
      "\u001b[0m\u001b[0;32m    186 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 187 \u001b[0;31m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_gvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    189 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"parse_query_obj\" generated code\n",
      "## context: \"objects = ['jar', 'lid']\"\n",
      "########################################\n",
      "objects = [\u001b[33m'\u001b[39;49;00m\u001b[33mjar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Query: left hand.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "left_hand = detect(\u001b[33m'\u001b[39;49;00m\u001b[33mleft hand\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ret_val = left_hand\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/LMP.py\u001b[0m(187)\u001b[0;36mexec_safe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    185 \u001b[0;31m    ])\n",
      "\u001b[0m\u001b[0;32m    186 \u001b[0;31m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 187 \u001b[0;31m        \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_gvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    189 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error executing code:\\n{code_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"get_affordance_map\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: a point at the center of the jar bottle.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "affordance_map = get_empty_affordance_map()\u001b[37m\u001b[39;49;00m\n",
      "jar_bottle = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "x, y, z = jar_bottle.position\u001b[37m\u001b[39;49;00m\n",
      "affordance_map[x, y, z] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "ret_val = affordance_map\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/LMP.py\u001b[0m(187)\u001b[0;36mexec_safe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    185 \u001b[0;31m    ])\n",
      "\u001b[0m\u001b[0;32m    186 \u001b[0;31m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 187 \u001b[0;31m        \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_gvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    189 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error executing code:\\n{code_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(using cache) *** OpenAI API call took 0.00s ***\n",
      "########################################\n",
      "## \"get_gripper_map\" generated code\n",
      "########################################\n",
      "\u001b[37m# Query: open everywhere except 1cm around the jar bottle.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "jar_bottle = parse_query_obj(\u001b[33m'\u001b[39;49;00m\u001b[33mjar bottle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "set_voxel_by_radius(gripper_map, jar_bottle.position, radius_cm=\u001b[34m1\u001b[39;49;00m, value=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ret_val = gripper_map\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n",
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/LMP.py\u001b[0m(187)\u001b[0;36mexec_safe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    185 \u001b[0;31m    ])\n",
      "\u001b[0m\u001b[0;32m    186 \u001b[0;31m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 187 \u001b[0;31m        \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_gvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    189 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error executing code:\\n{code_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/4TB-1/4TB-1/link_to_ssd/peract_repo/voxposer/interfaces.py\u001b[0m(94)\u001b[0;36mexecute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     92 \u001b[0;31m    \u001b[0;31m# initialize default voxel maps if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 94 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mrotation_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m      \u001b[0mrotation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_voxel_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rotation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mvelocity_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  rotation_map\n",
      "ipdb>  movable_obs_func()['name']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'left hand'\n"
     ]
    }
   ],
   "source": [
    "instruction = np.random.choice(descriptions)\n",
    "voxposer_ui(instruction)\n",
    "print('Is task successful ', env.task._scene.task.success()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3e8e1ce6146f4dbb0e1ef1d424d742293054e718434205b504bd28714852756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
